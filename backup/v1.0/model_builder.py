"""
ë¶„ì„ ëª¨ë¸ ìƒì„± ë° ì €ì¥ ëª¨ë“ˆ (ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ë²„ì „)
ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ í…Œì´ë¸”ì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ì„ ìƒì„±í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import pickle
import json
import requests
from datetime import datetime
import os
import warnings
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler
from database_manager import DatabaseManager
from log_config import get_logger
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logger = get_logger(__name__, 'model_builder.log')

class JobRecommendationModelBuilder:
    """ì±„ìš© ê³µê³  ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, data_source='database', api_url='http://mysite.com/recruits', scores_api_url='http://mysite.com/scores', csv_path='./data/all_data.csv'):
        """
        ëª¨ë¸ ë¹Œë” ì´ˆê¸°í™”
        
        Args:
            data_source (str): ë°ì´í„° ì†ŒìŠ¤ íƒ€ì… ('database', 'api' ë˜ëŠ” 'csv')
            api_url (str): ì±„ìš© ë°ì´í„° API ì—”ë“œí¬ì¸íŠ¸ URL (í•˜ìœ„ í˜¸í™˜ì„±)
            scores_api_url (str): ì ìˆ˜ ë°ì´í„° API ì—”ë“œí¬ì¸íŠ¸ URL (í•˜ìœ„ í˜¸í™˜ì„±)
            csv_path (str): CSV íŒŒì¼ ê²½ë¡œ (data_sourceê°€ 'csv'ì¼ ë•Œ ì‚¬ìš©)
        """
        self.data_source = data_source
        self.api_url = api_url
        self.scores_api_url = scores_api_url
        self.csv_path = csv_path
        self.score_columns = [
            'ì„±ì‹¤ì„±', 'ê°œë°©ì„±', 'ì™¸í–¥ì„±', 'ìš°í˜¸ì„±', 'ì •ì„œì•ˆì •ì„±', 'ê¸°ìˆ ì „ë¬¸ì„±', 
            'ì¸ì§€ë¬¸ì œí•´ê²°', 'ëŒ€ì¸-ì˜í–¥ë ¥', 'ìê¸°ê´€ë¦¬', 'ì ì‘ë ¥', 'í•™ìŠµì†ë„', 
            'ëŒ€ì¸ë¯¼ì²©ì„±', 'ì„±ê³¼ë¯¼ì²©ì„±', 'ìê¸°ì¸ì‹', 'ìê¸°ì¡°ì ˆ', 'ê³µê°-ì‚¬íšŒê¸°ìˆ '
        ]
        self.job_posting_scores = None  # ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ ë°ì´í„°
        self.scaler = StandardScaler()  # ì ìˆ˜ ì •ê·œí™”ë¥¼ ìœ„í•œ ìŠ¤ì¼€ì¼ëŸ¬
        self.model_info = {}
        
    def load_data_from_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ í…Œì´ë¸” ë¡œë”©"""
        try:
            print("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ ë°ì´í„° ë¡œë”© ì¤‘...")
            
            with DatabaseManager() as db:
                # ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ í…Œì´ë¸” ì¡°íšŒ
                query = """
                SELECT ê³µê³ ì¼ë ¨ë²ˆí˜¸, ê¸°ê´€ì½”ë“œ, ì¼ë°˜ì „í˜•,
                       ì„±ì‹¤ì„±, ê°œë°©ì„±, ì™¸í–¥ì„±, ìš°í˜¸ì„±, ì •ì„œì•ˆì •ì„±, ê¸°ìˆ ì „ë¬¸ì„±,
                       ì¸ì§€ë¬¸ì œí•´ê²°, `ëŒ€ì¸-ì˜í–¥ë ¥`, ìê¸°ê´€ë¦¬, ì ì‘ë ¥, í•™ìŠµì†ë„,
                       ëŒ€ì¸ë¯¼ì²©ì„±, ì„±ê³¼ë¯¼ì²©ì„±, ìê¸°ì¸ì‹, ìê¸°ì¡°ì ˆ, `ê³µê°-ì‚¬íšŒê¸°ìˆ `
                FROM ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜
                WHERE ì„±ì‹¤ì„± IS NOT NULL 
                AND ê°œë°©ì„± IS NOT NULL 
                AND ì™¸í–¥ì„± IS NOT NULL
                ORDER BY ê³µê³ ì¼ë ¨ë²ˆí˜¸
                """
                
                result = db.execute_query(query)
                if not result:
                    print("âŒ ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ í…Œì´ë¸”ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return False
                
                # DataFrameìœ¼ë¡œ ë³€í™˜
                columns = [
                    'ê³µê³ ì¼ë ¨ë²ˆí˜¸', 'ê¸°ê´€ì½”ë“œ', 'ì¼ë°˜ì „í˜•',
                    'ì„±ì‹¤ì„±', 'ê°œë°©ì„±', 'ì™¸í–¥ì„±', 'ìš°í˜¸ì„±', 'ì •ì„œì•ˆì •ì„±', 'ê¸°ìˆ ì „ë¬¸ì„±',
                    'ì¸ì§€ë¬¸ì œí•´ê²°', 'ëŒ€ì¸-ì˜í–¥ë ¥', 'ìê¸°ê´€ë¦¬', 'ì ì‘ë ¥', 'í•™ìŠµì†ë„',
                    'ëŒ€ì¸ë¯¼ì²©ì„±', 'ì„±ê³¼ë¯¼ì²©ì„±', 'ìê¸°ì¸ì‹', 'ìê¸°ì¡°ì ˆ', 'ê³µê°-ì‚¬íšŒê¸°ìˆ '
                ]
                
                self.job_posting_scores = pd.DataFrame(result, columns=columns)
                
                print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(self.job_posting_scores)}ê°œ ì±„ìš©ê³µê³ ")
                print(f"ğŸ“Š ì»¬ëŸ¼: {list(self.job_posting_scores.columns)}")
                print(f"ğŸ“‹ ê³ ìœ  ê¸°ê´€ ìˆ˜: {self.job_posting_scores['ê¸°ê´€ì½”ë“œ'].nunique()}")
                print(f"ğŸ“‹ ê³ ìœ  ì „í˜• ìˆ˜: {self.job_posting_scores['ì¼ë°˜ì „í˜•'].nunique()}")
                
                return True
                
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
        
    def load_data_from_api(self):
        """REST APIì—ì„œ ì±„ìš© ë°ì´í„° ë¡œë”©"""
        try:
            print(f"ğŸŒ APIì—ì„œ ì±„ìš© ë°ì´í„° ë¡œë”© ì¤‘: {self.api_url}")
            
            response = requests.get(self.api_url, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            # JSON ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            if isinstance(data, list):
                self.df_raw = pd.DataFrame(data)
            elif isinstance(data, dict) and 'data' in data:
                self.df_raw = pd.DataFrame(data['data'])
            elif isinstance(data, dict) and 'recruits' in data:
                self.df_raw = pd.DataFrame(data['recruits'])
            else:
                self.df_raw = pd.DataFrame([data])
            
            print(f"âœ… API ë°ì´í„° ë¡œë”© ì™„ë£Œ: {self.df_raw.shape[0]}ê°œ í–‰, {self.df_raw.shape[1]}ê°œ ì—´")
            print(f"ğŸ“Š ì»¬ëŸ¼: {list(self.df_raw.columns)}")
            return True
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {e}")
            print("ğŸ“‹ CSV íŒŒì¼ë¡œ ëŒ€ì²´í•˜ì—¬ ë¡œë”©ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            return self.load_data_from_csv()
        except Exception as e:
            print(f"âŒ API ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            print("ğŸ“‹ CSV íŒŒì¼ë¡œ ëŒ€ì²´í•˜ì—¬ ë¡œë”©ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            return self.load_data_from_csv()
    
    def load_data_from_csv(self):
        """CSV íŒŒì¼ì—ì„œ ì±„ìš© ë°ì´í„° ë¡œë”© (ë°±ì—… ë°©ë²•)"""
        try:
            print(f"ğŸ“‚ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë”© ì¤‘: {self.csv_path}")
            self.df_raw = pd.read_csv(self.csv_path, skiprows=1)
            print(f"âœ… CSV ë°ì´í„° ë¡œë”© ì™„ë£Œ: {self.df_raw.shape[0]}ê°œ í–‰, {self.df_raw.shape[1]}ê°œ ì—´")
            return True
        except Exception as e:
            print(f"âŒ CSV ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def load_data(self):
        """ë°ì´í„° ì†ŒìŠ¤ì— ë”°ë¼ ë°ì´í„° ë¡œë”©"""
        if self.data_source == 'database':
            return self.load_data_from_database()
        elif self.data_source == 'api':
            return self.load_data_from_api()
        else:
            return self.load_data_from_csv()
    
    def prepare_similarity_model(self):
        """ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œì„ ìœ„í•œ ëª¨ë¸ ì¤€ë¹„"""
        try:
            print("ğŸ”„ ìœ ì‚¬ë„ ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
            
            if self.job_posting_scores is None:
                print("âŒ ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ì ìˆ˜ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ ì •ê·œí™”
            score_data = self.job_posting_scores[self.score_columns].copy()
            
            # ê²°ì¸¡ê°’ ì²˜ë¦¬ (í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´)
            score_data = score_data.fillna(score_data.mean())
            
            # ë°ì´í„° ì •ê·œí™” (í‘œì¤€í™”)
            self.normalized_scores = self.scaler.fit_transform(score_data)
            
            print(f"âœ… ìœ ì‚¬ë„ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ: {len(self.normalized_scores)}ê°œ ê³µê³  ë°ì´í„°")
            return True
            
        except Exception as e:
            print(f"âŒ ìœ ì‚¬ë„ ëª¨ë¸ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return False
    
    def find_similar_job_postings(self, user_scores, top_k=5):
        """
        ì‚¬ìš©ì ì ìˆ˜ì™€ ìœ ì‚¬í•œ ì±„ìš©ê³µê³  ì°¾ê¸°
        
        Args:
            user_scores (dict): ì‚¬ìš©ìì˜ 16ê°€ì§€ ì ìˆ˜ {'ì„±ì‹¤ì„±': 4, 'ê°œë°©ì„±': 3, ...}
            top_k (int): ì¶”ì²œí•  ê³µê³  ìˆ˜
            
        Returns:
            list: ì¶”ì²œ ê³µê³ ì¼ë ¨ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if self.job_posting_scores is None or self.normalized_scores is None:
                print("âŒ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return []
            
            # ì‚¬ìš©ì ì ìˆ˜ë¥¼ ë°°ì—´ë¡œ ë³€í™˜ ë° ì •ê·œí™”
            user_score_array = np.array([user_scores.get(col, 3) for col in self.score_columns])
            user_score_normalized = self.scaler.transform([user_score_array])
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity(user_score_normalized, self.normalized_scores)[0]
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ kê°œ ì¶”ì¶œ
            top_indices = similarities.argsort()[-top_k:][::-1]
            
            # ì¶”ì²œ ê²°ê³¼ ìƒì„±
            recommendations = []
            for idx in top_indices:
                posting_info = {
                    'ê³µê³ ì¼ë ¨ë²ˆí˜¸': self.job_posting_scores.iloc[idx]['ê³µê³ ì¼ë ¨ë²ˆí˜¸'],
                    'ê¸°ê´€ì½”ë“œ': self.job_posting_scores.iloc[idx]['ê¸°ê´€ì½”ë“œ'],
                    'ì¼ë°˜ì „í˜•': self.job_posting_scores.iloc[idx]['ì¼ë°˜ì „í˜•'],
                    'ìœ ì‚¬ë„': float(similarities[idx])
                }
                recommendations.append(posting_info)
            
            print(f"âœ… ìœ ì‚¬í•œ ì±„ìš©ê³µê³  {len(recommendations)}ê°œ ì°¾ê¸° ì™„ë£Œ")
            return recommendations
            
        except Exception as e:
            print(f"âŒ ìœ ì‚¬ ê³µê³  ì°¾ê¸° ì‹¤íŒ¨: {e}")
            return []
    
    def preprocess_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬ - ë°ì´í„°ë² ì´ìŠ¤ ë°©ì‹ì—ì„œëŠ” ìœ ì‚¬ë„ ëª¨ë¸ ì¤€ë¹„"""
        if self.data_source == 'database':
            return self.prepare_similarity_model()
        else:
            # ê¸°ì¡´ API/CSV ë°©ì‹
            return self.preprocess_data_legacy()
    
    def preprocess_data_legacy(self):
        """ë°ì´í„° ì „ì²˜ë¦¬ - ì¼ë°˜ì „í˜• ë¶„ë¦¬ ë° í™•ì¥ (ê¸°ì¡´ ë°©ì‹)"""
        try:
            print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
            
            # 'ì¼ë°˜ì „í˜•' ì»¬ëŸ¼ì„ ','ë¡œ ë¶„ë¦¬í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df_new = self.df_raw[['ê¸°ê´€ëª…', 'ì¼ë°˜ì „í˜•']].copy()
            df_new = df_new[df_new['ì¼ë°˜ì „í˜•'].notna()]
            
            # ì „í˜• ë°ì´í„° í™•ì¥
            df_expanded = []
            for idx, row in df_new.iterrows():
                ê¸°ê´€ëª… = row['ê¸°ê´€ëª…']
                ì¼ë°˜ì „í˜•_text = str(row['ì¼ë°˜ì „í˜•'])
                
                ì¼ë°˜ì „í˜•_lines = ì¼ë°˜ì „í˜•_text.split('\n')
                
                for line in ì¼ë°˜ì „í˜•_lines:
                    ì „í˜•_list = line.split(',')
                    for ì „í˜• in ì „í˜•_list:
                        ì „í˜• = ì „í˜•.strip()
                        if ì „í˜•:
                            df_expanded.append({
                                'ê¸°ê´€ëª…': ê¸°ê´€ëª…,
                                'ì¼ë°˜ì „í˜•': ì „í˜•
                            })
            
            self.df_processed = pd.DataFrame(df_expanded)
            self.df_processed = self.df_processed.drop_duplicates(subset=['ê¸°ê´€ëª…', 'ì¼ë°˜ì „í˜•'])
            
            print(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: {len(self.df_processed)}ê°œ ê¸°ê´€-ì „í˜• ì¡°í•©")
            print(f"ğŸ“‹ ê³ ìœ  ê¸°ê´€ ìˆ˜: {self.df_processed['ê¸°ê´€ëª…'].nunique()}")
            print(f"ğŸ“‹ ê³ ìœ  ì „í˜• ìˆ˜: {self.df_processed['ì¼ë°˜ì „í˜•'].nunique()}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    def load_scores_from_api(self):
        """REST APIì—ì„œ ì ìˆ˜ ë°ì´í„° ë¡œë”©"""
        try:
            print(f"ğŸ¯ APIì—ì„œ ì ìˆ˜ ë°ì´í„° ë¡œë”© ì¤‘: {self.scores_api_url}")
            
            response = requests.get(self.scores_api_url, timeout=30)
            
            # HTTP ìƒíƒœ ì½”ë“œ í™•ì¸í•˜ë˜, 500 ì—ëŸ¬ì—¬ë„ ì‘ë‹µ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if response.status_code == 200:
                data = response.json()
            elif response.status_code == 500:
                # 500 ì—ëŸ¬ì´ì§€ë§Œ JSON ì‘ë‹µì´ ìˆëŠ” ê²½ìš° (ìƒ˜í”Œ ë°ì´í„° ë“±)
                try:
                    data = response.json()
                    if 'data' in data and data['data']:
                        print(f"âš ï¸ API ì„œë²„ ì˜¤ë¥˜(500)ì´ì§€ë§Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {data.get('message', '')}")
                    else:
                        raise ValueError("ì‘ë‹µì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                except (ValueError, KeyError):
                    response.raise_for_status()  # ì •ìƒì ì¸ 500 ì—ëŸ¬ë¡œ ì²˜ë¦¬
            else:
                response.raise_for_status()
            
            # JSON ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            if isinstance(data, list):
                scores_df = pd.DataFrame(data)
            elif isinstance(data, dict) and 'data' in data:
                scores_df = pd.DataFrame(data['data'])
            elif isinstance(data, dict) and 'scores' in data:
                scores_df = pd.DataFrame(data['scores'])
            else:
                scores_df = pd.DataFrame([data])
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_columns = ['ê¸°ê´€ëª…', 'ì¼ë°˜ì „í˜•'] + self.score_columns
            missing_columns = [col for col in required_columns if col not in scores_df.columns]
            
            if missing_columns:
                print(f"âŒ API ì ìˆ˜ ë°ì´í„°ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
                print("ğŸ”„ ìë™ ì ìˆ˜ ìƒì„±ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
                return False
            
            # df_processedì™€ ë§¤ì¹­í•˜ì—¬ ì ìˆ˜ ë°ì´í„° ìƒì„±
            merged_df = self.df_processed.merge(
                scores_df[required_columns], 
                on=['ê¸°ê´€ëª…', 'ì¼ë°˜ì „í˜•'], 
                how='left'
            )
            
            # ë§¤ì¹­ë˜ì§€ ì•Šì€ ë°ì´í„° í™•ì¸
            missing_scores = merged_df[merged_df[self.score_columns[0]].isna()]
            
            if len(missing_scores) > 0:
                print(f"âš ï¸ APIì—ì„œ ì ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì „í˜•: {len(missing_scores)}ê°œ")
                print("ğŸ”„ ëˆ„ë½ëœ ì „í˜•ì— ëŒ€í•´ ìë™ ì ìˆ˜ ìƒì„±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
                
                # ëˆ„ë½ëœ ì „í˜•ì— ëŒ€í•´ ìë™ ì ìˆ˜ ìƒì„±
                for idx in missing_scores.index:
                    form = merged_df.loc[idx, 'ì¼ë°˜ì „í˜•']
                    for column in self.score_columns:
                        if pd.isna(merged_df.loc[idx, column]):
                            merged_df.loc[idx, column] = self._generate_score_for_form(form, column)
            
            self.df_scores = merged_df
            print(f"âœ… API ì ìˆ˜ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(self.df_scores)}ê°œ ì „í˜• í”„ë¡œíŒŒì¼")
            print(f"ğŸ“Š APIì—ì„œ ë¡œë”©ëœ ì „í˜•: {len(self.df_scores) - len(missing_scores)}ê°œ")
            if len(missing_scores) > 0:
                print(f"ğŸ”„ ìë™ ìƒì„±ëœ ì „í˜•: {len(missing_scores)}ê°œ")
            
            return True
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ ì ìˆ˜ API ìš”ì²­ ì‹¤íŒ¨: {e}")
            print("ğŸ”„ ìë™ ì ìˆ˜ ìƒì„±ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
            return False
        except Exception as e:
            print(f"âŒ ì ìˆ˜ API ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            print("ğŸ”„ ìë™ ì ìˆ˜ ìƒì„±ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
            return False
    
    def _generate_score_for_form(self, form, column):
        """ê°œë³„ ì „í˜•-ì»¬ëŸ¼ì— ëŒ€í•œ ì ìˆ˜ ìƒì„±"""
        # ê¸°ì¡´ generate_scores ë¡œì§ì—ì„œ ì¶”ì¶œí•œ ì ìˆ˜ ìƒì„± ê·œì¹™
        if 'ìš´ì˜' in form or 'ì‚¬ë¬´' in form:
            if column in ['ì„±ì‹¤ì„±', 'ìê¸°ê´€ë¦¬', 'ëŒ€ì¸-ì˜í–¥ë ¥', 'ê³µê°-ì‚¬íšŒê¸°ìˆ ']:
                return np.random.randint(3, 6)
            else:
                return np.random.randint(2, 5)
        elif any(keyword in form for keyword in ['ê¸°ìˆ ', 'ì „ê¸°', 'ê¸°ê³„', 'í† ëª©', 'ê±´ì¶•', 'í†µì‹ ', 'ì‹ í˜¸']):
            if column in ['ê¸°ìˆ ì „ë¬¸ì„±', 'ì¸ì§€ë¬¸ì œí•´ê²°', 'í•™ìŠµì†ë„', 'ìê¸°ê´€ë¦¬']:
                return np.random.randint(3, 6)
            else:
                return np.random.randint(2, 5)
        elif 'ìš´ì „' in form:
            if column in ['ì„±ì‹¤ì„±', 'ì •ì„œì•ˆì •ì„±', 'ì ì‘ë ¥', 'ìê¸°ê´€ë¦¬']:
                return np.random.randint(3, 6)
            else:
                return np.random.randint(2, 5)
        elif 'ê³µë¬´' in form:
            if column in ['ì„±ì‹¤ì„±', 'ê¸°ìˆ ì „ë¬¸ì„±', 'ìê¸°ê´€ë¦¬']:
                return np.random.randint(3, 6)
            else:
                return np.random.randint(2, 5)
        else:
            return np.random.randint(2, 5)
    
    def generate_scores_from_rules(self):
        """ì „í˜•ë³„ íŠ¹ì„±í™”ëœ ì ìˆ˜ ìƒì„± (ê¸°ì¡´ ë°©ì‹)"""
        try:
            print("ğŸ¯ ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ ìƒì„± ì¤‘...")
            
            self.df_scores = self.df_processed.copy()
            
            # ì¼ë°˜ì „í˜•ë³„ ê¸°ì¤€ ì ìˆ˜ ìƒì„±
            np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
            unique_forms = self.df_processed['ì¼ë°˜ì „í˜•'].unique()
            base_scores = {}
            
            for form in unique_forms:
                base_scores[form] = {}
                for column in self.score_columns:
                    base_scores[form][column] = self._generate_score_for_form(form, column)
            
            # ê° í–‰ì— ëŒ€í•´ ê¸°ì¤€ ì ìˆ˜ì—ì„œ ì•½ê°„ì˜ ë³€ë™ì„ ê°€ì§„ ì ìˆ˜ í• ë‹¹
            for idx, row in self.df_scores.iterrows():
                form = row['ì¼ë°˜ì „í˜•']
                for column in self.score_columns:
                    base_score = base_scores[form][column]
                    # ê¸°ì¤€ ì ìˆ˜ì—ì„œ Â±1 ë²”ìœ„ì˜ ë³€ë™ (1~5 ë²”ìœ„ ìœ ì§€)
                    variation = np.random.randint(-1, 2)
                    final_score = max(1, min(5, base_score + variation))
                    self.df_scores.loc[idx, column] = final_score
            
            print(f"âœ… ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ ìƒì„± ì™„ë£Œ: {len(self.df_scores)}ê°œ ì „í˜• í”„ë¡œíŒŒì¼")
            return True
            
        except Exception as e:
            print(f"âŒ ì ìˆ˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def generate_scores(self):
        """ì ìˆ˜ ìƒì„± - ë°ì´í„°ë² ì´ìŠ¤ ë°©ì‹ì—ì„œëŠ” ìŠ¤í‚µ (ì´ë¯¸ ì ìˆ˜ê°€ ìˆìŒ)"""
        if self.data_source == 'database':
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ë°©ì‹: ì ìˆ˜ ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            return True
        else:
            # ê¸°ì¡´ API/CSV ë°©ì‹
            if self.data_source == 'api':
                # API ëª¨ë“œì¼ ë•Œ ì ìˆ˜ API ì‹œë„
                if self.load_scores_from_api():
                    return True
                else:
                    print("ğŸ“‹ ì ìˆ˜ API ì‹¤íŒ¨ë¡œ ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ ìƒì„±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
                    return self.generate_scores_from_rules()
            else:
                # CSV ëª¨ë“œì¼ ë•ŒëŠ” ê·œì¹™ ê¸°ë°˜ ìƒì„±
                return self.generate_scores_from_rules()
    
    def create_form_profiles(self):
        """ì „í˜•ë³„ í‰ê·  í”„ë¡œíŒŒì¼ ìƒì„±"""
        if self.data_source == 'database':
            return self.create_database_profiles()
        else:
            return self.create_legacy_profiles()
    
    def create_database_profiles(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë°©ì‹: ê¸°ê´€ì½”ë“œë³„ ì „í˜• í”„ë¡œíŒŒì¼ ìƒì„±"""
        try:
            print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ í”„ë¡œíŒŒì¼ ìƒì„± ì¤‘...")
            
            if self.job_posting_scores is None:
                print("âŒ ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ê¸°ê´€ì½”ë“œ + ì¼ë°˜ì „í˜•ë³„ í‰ê·  ì ìˆ˜ ê³„ì‚°
            self.form_profiles = self.job_posting_scores.groupby(['ê¸°ê´€ì½”ë“œ', 'ì¼ë°˜ì „í˜•'])[self.score_columns].mean()
            
            # ì „í˜•ë³„ í†µê³„ ì •ë³´ë„ ìƒì„±
            self.form_stats = {
                'total_postings': len(self.job_posting_scores),
                'unique_agencies': self.job_posting_scores['ê¸°ê´€ì½”ë“œ'].nunique(),
                'unique_forms': self.job_posting_scores['ì¼ë°˜ì „í˜•'].nunique(),
                'agency_form_combinations': len(self.form_profiles)
            }
            
            print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ í”„ë¡œíŒŒì¼ ìƒì„± ì™„ë£Œ:")
            print(f"   ğŸ“‹ ì´ ê³µê³  ìˆ˜: {self.form_stats['total_postings']}")
            print(f"   ğŸ¢ ê³ ìœ  ê¸°ê´€ ìˆ˜: {self.form_stats['unique_agencies']}")
            print(f"   ğŸ“ ê³ ìœ  ì „í˜• ìˆ˜: {self.form_stats['unique_forms']}")
            print(f"   ğŸ”— ê¸°ê´€-ì „í˜• ì¡°í•©: {self.form_stats['agency_form_combinations']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ í”„ë¡œíŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def create_legacy_profiles(self):
        """ê¸°ì¡´ ë°©ì‹: ì „í˜•ë³„ í‰ê·  í”„ë¡œíŒŒì¼ ìƒì„±"""
        try:
            print("ğŸ“Š ì „í˜•ë³„ í”„ë¡œíŒŒì¼ ìƒì„± ì¤‘...")
            
            # ì „í˜•ë³„ í‰ê·  ì ìˆ˜ ê³„ì‚°
            self.form_profiles = self.df_scores.groupby('ì¼ë°˜ì „í˜•')[self.score_columns].mean()
            
            print(f"âœ… ì „í˜• í”„ë¡œíŒŒì¼ ìƒì„± ì™„ë£Œ: {len(self.form_profiles)}ê°œ ì „í˜•")
            return True
            
        except Exception as e:
            print(f"âŒ ì „í˜• í”„ë¡œíŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def save_model(self, model_dir='./models'):
        """ëª¨ë¸ ì €ì¥"""
        try:
            print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
            
            # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(model_dir, exist_ok=True)
            
            # í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ë²„ì „ ì •ë³´ ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            if self.data_source == 'database':
                # ë°ì´í„°ë² ì´ìŠ¤ ë°©ì‹ ëª¨ë¸ ì •ë³´
                self.model_info = {
                    'version': f'v{timestamp}',
                    'created_at': datetime.now().isoformat(),
                    'data_source': {
                        'source_type': 'database',
                        'table_name': 'ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜'
                    },
                    'total_postings': self.form_stats['total_postings'],
                    'unique_agencies': self.form_stats['unique_agencies'],
                    'unique_forms': self.form_stats['unique_forms'],
                    'agency_form_combinations': self.form_stats['agency_form_combinations'],
                    'score_columns': self.score_columns,
                    'model_type': 'similarity_based_recommendation'
                }
                
                # 1. ìœ ì‚¬ë„ ëª¨ë¸ ì €ì¥ (ìŠ¤ì¼€ì¼ëŸ¬ + ì •ê·œí™”ëœ ì ìˆ˜)
                similarity_model = {
                    'scaler': self.scaler,
                    'normalized_scores': self.normalized_scores,
                    'job_posting_scores': self.job_posting_scores
                }
                similarity_path = os.path.join(model_dir, 'similarity_model.pkl')
                with open(similarity_path, 'wb') as f:
                    pickle.dump(similarity_model, f)
                
                # 2. ì „í˜• í”„ë¡œíŒŒì¼ ì €ì¥ (pickle)
                profile_path = os.path.join(model_dir, 'form_profiles.pkl')
                with open(profile_path, 'wb') as f:
                    pickle.dump(self.form_profiles, f)
                
                print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
                print(f"   ğŸ“ ë””ë ‰í† ë¦¬: {model_dir}")
                print(f"   ğŸ¯ ìœ ì‚¬ë„ ëª¨ë¸: {similarity_path}")
                print(f"   ğŸ“Š ì „í˜• í”„ë¡œíŒŒì¼: {profile_path}")
                
            else:
                # ê¸°ì¡´ API/CSV ë°©ì‹
                data_source_info = {
                    'source_type': self.data_source,
                    'api_url': self.api_url if self.data_source == 'api' else None,
                    'scores_api_url': self.scores_api_url if self.data_source == 'api' else None,
                    'csv_path': self.csv_path if self.data_source == 'csv' else None
                }
                
                self.model_info = {
                    'version': f'v{timestamp}',
                    'created_at': datetime.now().isoformat(),
                    'data_source': data_source_info,
                    'total_records': len(self.df_raw),
                    'processed_records': len(self.df_processed),
                    'unique_forms': len(self.form_profiles),
                    'unique_organizations': self.df_processed['ê¸°ê´€ëª…'].nunique(),
                    'score_columns': self.score_columns,
                    'model_type': 'legacy_form_based'
                }
                
                # 1. ì „í˜• í”„ë¡œíŒŒì¼ ì €ì¥ (pickle)
                profile_path = os.path.join(model_dir, 'form_profiles.pkl')
                with open(profile_path, 'wb') as f:
                    pickle.dump(self.form_profiles, f)
                
                # 2. ì ìˆ˜ ë°ì´í„° ì €ì¥ (pickle)
                scores_path = os.path.join(model_dir, 'scores_data.pkl')
                with open(scores_path, 'wb') as f:
                    pickle.dump(self.df_scores, f)
                
                print(f"âœ… ë ˆê±°ì‹œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
                print(f"   ğŸ“ ë””ë ‰í† ë¦¬: {model_dir}")
                print(f"   ğŸ“Š ì „í˜• í”„ë¡œíŒŒì¼: {profile_path}")
                print(f"   ğŸ“ˆ ì ìˆ˜ ë°ì´í„°: {scores_path}")
            
            # 3. ëª¨ë¸ ì •ë³´ ì €ì¥ (JSON) - ê³µí†µ
            info_path = os.path.join(model_dir, 'model_info.json')
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(self.model_info, f, ensure_ascii=False, indent=2)
            
            # 4. ì¶”ì²œ í•¨ìˆ˜ ì €ì¥ (ë°ì´í„°ë² ì´ìŠ¤ ë°©ì‹ì—ì„œë§Œ)
            if self.data_source == 'database':
                recommendation_function = """
def recommend_job_postings(user_scores, model_dir='./models', top_k=5):
    \"\"\"
    ì‚¬ìš©ì ì ìˆ˜ë¥¼ ë°›ì•„ ìœ ì‚¬í•œ ì±„ìš©ê³µê³  ì¶”ì²œ
    
    Args:
        user_scores (dict): ì‚¬ìš©ìì˜ 16ê°€ì§€ ì ìˆ˜
        model_dir (str): ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        top_k (int): ì¶”ì²œí•  ê³µê³  ìˆ˜
    
    Returns:
        list: ì¶”ì²œ ê³µê³ ì¼ë ¨ë²ˆí˜¸ì™€ ìœ ì‚¬ë„ ì •ë³´
    \"\"\"
    import pickle
    import numpy as np
    from sklearn.metrics.pairwise import cosine_similarity
    
    # ëª¨ë¸ ë¡œë”©
    with open(f'{model_dir}/similarity_model.pkl', 'rb') as f:
        model = pickle.load(f)
    
    scaler = model['scaler']
    normalized_scores = model['normalized_scores']
    job_posting_scores = model['job_posting_scores']
    
    score_columns = [
        'ì„±ì‹¤ì„±', 'ê°œë°©ì„±', 'ì™¸í–¥ì„±', 'ìš°í˜¸ì„±', 'ì •ì„œì•ˆì •ì„±', 'ê¸°ìˆ ì „ë¬¸ì„±',
        'ì¸ì§€ë¬¸ì œí•´ê²°', 'ëŒ€ì¸-ì˜í–¥ë ¥', 'ìê¸°ê´€ë¦¬', 'ì ì‘ë ¥', 'í•™ìŠµì†ë„',
        'ëŒ€ì¸ë¯¼ì²©ì„±', 'ì„±ê³¼ë¯¼ì²©ì„±', 'ìê¸°ì¸ì‹', 'ìê¸°ì¡°ì ˆ', 'ê³µê°-ì‚¬íšŒê¸°ìˆ '
    ]
    
    # ì‚¬ìš©ì ì ìˆ˜ ì •ê·œí™”
    user_score_array = np.array([user_scores.get(col, 3) for col in score_columns])
    user_score_normalized = scaler.transform([user_score_array])
    
    # ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity(user_score_normalized, normalized_scores)[0]
    
    # ìƒìœ„ kê°œ ì¶”ì²œ
    top_indices = similarities.argsort()[-top_k:][::-1]
    
    recommendations = []
    for idx in top_indices:
        recommendations.append({
            'ê³µê³ ì¼ë ¨ë²ˆí˜¸': job_posting_scores.iloc[idx]['ê³µê³ ì¼ë ¨ë²ˆí˜¸'],
            'ê¸°ê´€ì½”ë“œ': job_posting_scores.iloc[idx]['ê¸°ê´€ì½”ë“œ'],
            'ì¼ë°˜ì „í˜•': job_posting_scores.iloc[idx]['ì¼ë°˜ì „í˜•'],
            'ìœ ì‚¬ë„': float(similarities[idx])
        })
    
    return recommendations
"""
                func_path = os.path.join(model_dir, 'recommendation_function.py')
                with open(func_path, 'w', encoding='utf-8') as f:
                    f.write(recommendation_function)
                
                print(f"   ğŸ¯ ì¶”ì²œ í•¨ìˆ˜: {func_path}")
            
            print(f"   â„¹ï¸ ëª¨ë¸ ì •ë³´: {info_path}")
            print(f"   ğŸ·ï¸ ë²„ì „: {self.model_info['version']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def build_and_save_model(self, model_dir='./models'):
        """ì „ì²´ ëª¨ë¸ ë¹Œë“œ ë° ì €ì¥ í”„ë¡œì„¸ìŠ¤"""
        print("ğŸš€ ì±„ìš© ì „í˜• ì¶”ì²œ ëª¨ë¸ ë¹Œë“œ ì‹œì‘")
        print("=" * 50)
        
        steps = [
            ("ë°ì´í„° ë¡œë”©", self.load_data),
            ("ë°ì´í„° ì „ì²˜ë¦¬", self.preprocess_data),
            ("ì ìˆ˜ ìƒì„±", self.generate_scores),
            ("í”„ë¡œíŒŒì¼ ìƒì„±", self.create_form_profiles),
            ("ëª¨ë¸ ì €ì¥", lambda: self.save_model(model_dir))
        ]
        
        for step_name, step_func in steps:
            if not step_func():
                print(f"âŒ {step_name} ë‹¨ê³„ì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return False
        
        print("\n" + "=" * 50)
        print("ğŸ‰ ëª¨ë¸ ë¹Œë“œ ë° ì €ì¥ ì™„ë£Œ!")
        print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
        print(f"   - ë²„ì „: {self.model_info['version']}")
        
        if self.data_source == 'database':
            print(f"   - ì´ ê³µê³  ìˆ˜: {self.model_info.get('total_postings', 'N/A')}")
            print(f"   - ê¸°ê´€ ìˆ˜: {self.model_info.get('unique_agencies', 'N/A')}")
            print(f"   - ì „í˜• ìˆ˜: {self.model_info.get('unique_forms', 'N/A')}")
        else:
            print(f"   - ì „í˜• ìˆ˜: {self.model_info.get('unique_forms', 'N/A')}")
            print(f"   - ê¸°ê´€ ìˆ˜: {self.model_info.get('unique_organizations', 'N/A')}")
            print(f"   - ë°ì´í„° ë ˆì½”ë“œ: {self.model_info.get('processed_records', 'N/A')}")
        
        return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì±„ìš© ì „í˜• ì¶”ì²œ ëª¨ë¸ ë¹Œë”')
    parser.add_argument('--source', choices=['database', 'api', 'csv'], default='database', 
                        help='ë°ì´í„° ì†ŒìŠ¤ (database: MariaDB ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ í…Œì´ë¸”, api: REST API, csv: CSV íŒŒì¼)')
    parser.add_argument('--api-url', default='http://mysite.com/recruits',
                        help='ì±„ìš© ë°ì´í„° API URL (ë ˆê±°ì‹œ)')
    parser.add_argument('--scores-api-url', default='http://mysite.com/scores',
                        help='ì ìˆ˜ ë°ì´í„° API URL (ë ˆê±°ì‹œ)')
    parser.add_argument('--csv-path', default='./data/all_data.csv',
                        help='CSV íŒŒì¼ ê²½ë¡œ (ë ˆê±°ì‹œ)')
    parser.add_argument('--output-dir', default='./models',
                        help='ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    print("ğŸš€ ì±„ìš© ê³µê³  ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ ë¹Œë” ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“¡ ë°ì´í„° ì†ŒìŠ¤: {args.source.upper()}")
    
    if args.source == 'database':
        print("ğŸ—„ï¸ MariaDB ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ë¡œë”©")
        print("ğŸ¯ ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬ì¶•")
        print("ğŸ“Š 16ê°€ì§€ ì ìˆ˜ë¥¼ í†µí•œ ê°œì¸í™”ëœ ê³µê³  ì¶”ì²œ")
    elif args.source == 'api':
        print(f"ğŸŒ ì±„ìš© ë°ì´í„° API: {args.api_url}")
        print(f"ğŸ¯ ì ìˆ˜ ë°ì´í„° API: {args.scores_api_url}")
        print("ğŸ“‹ ë°±ì—…: CSV íŒŒì¼ ì‚¬ìš© (API ì‹¤íŒ¨ ì‹œ)")
    else:
        print(f"ğŸ“‚ CSV íŒŒì¼: {args.csv_path}")
    
    print(f"ğŸ’¾ ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output_dir}")
    print("=" * 60)
    
    # ëª¨ë¸ ë¹Œë” ìƒì„±
    builder = JobRecommendationModelBuilder(
        data_source=args.source,
        api_url=args.api_url,
        scores_api_url=args.scores_api_url,
        csv_path=args.csv_path
    )
    
    # ëª¨ë¸ ë¹Œë“œ ë° ì €ì¥
    if builder.build_and_save_model(args.output_dir):
        print("\nâœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ê³  ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        if args.source == 'database':
            print("\nğŸ¯ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ ì‚¬ìš©ë²•:")
            print("   1. ì‚¬ìš©ìì˜ 16ê°€ì§€ ì ìˆ˜ ì…ë ¥")
            print("   2. from models.recommendation_function import recommend_job_postings")
            print("   3. recommendations = recommend_job_postings(user_scores)")
            print("\nğŸ“‹ ì‚¬ìš©ì ì ìˆ˜ í˜•ì‹:")
            print("   user_scores = {")
            print("       'ì„±ì‹¤ì„±': 4, 'ê°œë°©ì„±': 3, 'ì™¸í–¥ì„±': 5, ...")
            print("       # 16ê°€ì§€ ëª¨ë“  ì ìˆ˜ í¬í•¨")
            print("   }")
            print(f"\nï¿½ ëª¨ë¸ ì •ë³´:")
            print(f"   - ì´ ì±„ìš©ê³µê³ : {builder.model_info.get('total_postings', 'N/A')}")
            print(f"   - ê¸°ê´€ ìˆ˜: {builder.model_info.get('unique_agencies', 'N/A')}")
            print(f"   - ì „í˜• ìˆ˜: {builder.model_info.get('unique_forms', 'N/A')}")
        else:
            print("ï¿½ğŸ’¡ ì´ì œ API ì„œë²„ì—ì„œ ì´ ëª¨ë¸ì„ ë¡œë”©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            if args.source == 'api':
                print("\nğŸ”„ ëª¨ë¸ ì—…ë°ì´íŠ¸ ë°©ë²•:")
                print("   1. ìƒˆë¡œìš´ ì±„ìš© ë°ì´í„°ê°€ APIì— ì¶”ê°€ë˜ë©´")
                print("   2. python3 model_builder.py --source api")
                print("   3. curl -X POST http://localhost:8080/reload_model")
                print("\nğŸ¯ ì ìˆ˜ ë°ì´í„° API í˜•ì‹:")
                print("   GET /scores ì‘ë‹µ ì˜ˆì‹œ:")
                print('   [{"ê¸°ê´€ëª…": "ê¸°ê´€ëª…", "ì¼ë°˜ì „í˜•": "ì „í˜•ëª…", "ì„±ì‹¤ì„±": 4, "ê°œë°©ì„±": 3, ...}]')
    else:
        print("\nâŒ ëª¨ë¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        if args.source == 'database':
            print("ğŸ’¡ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë˜ëŠ” í…Œì´ë¸” ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("   - MariaDB ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸")
            print("   - ì±„ìš©ê³µê³ í‰ê°€ì ìˆ˜ í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸")
            print("   - í…Œì´ë¸”ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸")
        elif args.source == 'api':
            print("ğŸ’¡ API ì—°ê²° ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. CSV ëª¨ë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”:")
            print("   python3 model_builder.py --source csv")

if __name__ == "__main__":
    main()
