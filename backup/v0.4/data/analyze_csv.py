"""
CSV íŒŒì¼ ë¶„ì„ ë° í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ë¯¸ë¦¬ë³´ê¸°
ì‹¤ì œ í…Œì´ë¸” ìƒì„± ì „ì— ì–´ë–¤ êµ¬ì¡°ë¡œ ìƒì„±ë ì§€ ë¯¸ë¦¬ í™•ì¸
"""

import os
import pandas as pd
import re
from datetime import datetime

def clean_column_name(col_name):
    """ì»¬ëŸ¼ëª…ì„ MySQL í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬"""
    cleaned = re.sub(r'[^\wê°€-í£]', '_', str(col_name).strip())
    cleaned = re.sub(r'_+', '_', cleaned)
    cleaned = cleaned.strip('_')
    if not cleaned:
        cleaned = 'column_name'
    if cleaned[0].isdigit():
        cleaned = 'col_' + cleaned
    return cleaned

def infer_mysql_type(series, col_name):
    """pandas Seriesë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ MySQL ë°ì´í„° íƒ€ì… ì¶”ë¡ """
    non_null_series = series.dropna()
    
    if len(non_null_series) == 0:
        return "TEXT", "ëª¨ë“  ê°’ì´ NULL"
    
    # ë‚ ì§œ íƒ€ì… í™•ì¸
    if any(keyword in col_name.lower() for keyword in ['ë‚ ì§œ', 'date', 'ì‹œì‘ì¼', 'ë§ˆê°ì¼', 'ì—°ë„']):
        if col_name == 'ì—°ë„':
            return "YEAR", "ì—°ë„ í•„ë“œ"
        return "DATE", "ë‚ ì§œ í•„ë“œ"
    
    # ìˆ«ì íƒ€ì… í™•ì¸
    if pd.api.types.is_numeric_dtype(series):
        if pd.api.types.is_integer_dtype(series):
            max_val = non_null_series.max()
            min_val = non_null_series.min()
            
            if min_val >= 0 and max_val <= 255:
                return "TINYINT UNSIGNED", f"ë²”ìœ„: {min_val}-{max_val}"
            elif min_val >= -128 and max_val <= 127:
                return "TINYINT", f"ë²”ìœ„: {min_val}-{max_val}"
            elif min_val >= 0 and max_val <= 65535:
                return "SMALLINT UNSIGNED", f"ë²”ìœ„: {min_val}-{max_val}"
            elif min_val >= -32768 and max_val <= 32767:
                return "SMALLINT", f"ë²”ìœ„: {min_val}-{max_val}"
            elif min_val >= 0 and max_val <= 4294967295:
                return "INT UNSIGNED", f"ë²”ìœ„: {min_val}-{max_val}"
            elif min_val >= -2147483648 and max_val <= 2147483647:
                return "INT", f"ë²”ìœ„: {min_val}-{max_val}"
            else:
                return "BIGINT", f"ë²”ìœ„: {min_val}-{max_val}"
        else:
            return "DECIMAL(10,2)", f"ë¶€ë™ì†Œìˆ˜ì  ë²”ìœ„: {non_null_series.min():.2f}-{non_null_series.max():.2f}"
    
    # ë¬¸ìì—´ íƒ€ì…
    if pd.api.types.is_object_dtype(series):
        max_length = non_null_series.astype(str).str.len().max()
        avg_length = non_null_series.astype(str).str.len().mean()
        
        if max_length <= 50:
            return f"VARCHAR({min(255, max_length * 2)})", f"í‰ê·  ê¸¸ì´: {avg_length:.1f}, ìµœëŒ€: {max_length}"
        elif max_length <= 255:
            return "VARCHAR(255)", f"í‰ê·  ê¸¸ì´: {avg_length:.1f}, ìµœëŒ€: {max_length}"
        elif max_length <= 65535:
            return "TEXT", f"í‰ê·  ê¸¸ì´: {avg_length:.1f}, ìµœëŒ€: {max_length}"
        else:
            return "LONGTEXT", f"í‰ê·  ê¸¸ì´: {avg_length:.1f}, ìµœëŒ€: {max_length}"
    
    return "TEXT", "ê¸°ë³¸ í…ìŠ¤íŠ¸ íƒ€ì…"

def analyze_csv_file(file_path):
    """CSV íŒŒì¼ ë¶„ì„"""
    try:
        print(f"\nğŸ“ íŒŒì¼ ë¶„ì„: {os.path.basename(file_path)}")
        print("=" * 80)
        
        # CSV íŒŒì¼ ì½ê¸° (ì¸ì½”ë”© ìë™ ê°ì§€)
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
        except UnicodeDecodeError:
            try:
                df = pd.read_csv(file_path, encoding='cp949')
            except UnicodeDecodeError:
                df = pd.read_csv(file_path, encoding='euc-kr')
        
        print(f"ğŸ“Š ì›ë³¸ í¬ê¸°: {df.shape[0]}í–‰ x {df.shape[1]}ì—´")
        
        # ë¹ˆ í–‰ ì œê±°
        df = df.dropna(how='all')
        
        # í—¤ë”ê°€ ì—†ëŠ” ê²½ìš° í™•ì¸ (ì²« ë²ˆì§¸ í–‰ì´ ë°ì´í„°ì¸ì§€ í™•ì¸)
        if df.iloc[0].astype(str).str.contains('ì±„ìš©ì •ë³´|í˜„í™©|ê¸°ê´€ëª…').any():
            if len(df) > 1:
                print("ğŸ”§ ì²« ë²ˆì§¸ í–‰ì„ ì œëª©ìœ¼ë¡œ, ë‘ ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ì²˜ë¦¬")
                df.columns = df.iloc[1]
                df = df.iloc[2:].reset_index(drop=True)
            else:
                df = df.iloc[1:].reset_index(drop=True)
        
        # ë¹ˆ ì»¬ëŸ¼ ì œê±°
        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
        df = df.dropna(axis=1, how='all')
        
        if df.empty:
            print("âš ï¸ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"ğŸ“Š ì •ë¦¬ëœ í¬ê¸°: {df.shape[0]}í–‰ x {df.shape[1]}ì—´")
        
        # í…Œì´ë¸”ëª… ìƒì„±
        table_name = os.path.splitext(os.path.basename(file_path))[0]
        
        print(f"\nğŸ—ï¸ ìƒì„±ë  í…Œì´ë¸”ëª…: {table_name}")
        print(f"\nğŸ“‹ ì»¬ëŸ¼ ë¶„ì„:")
        print("-" * 120)
        print(f"{'ì›ë³¸ ì»¬ëŸ¼ëª…':<25} {'ì •ë¦¬ëœ ì»¬ëŸ¼ëª…':<25} {'MySQL íƒ€ì…':<20} {'NULLë¹„ìœ¨':<10} {'ìƒì„¸ì •ë³´':<30}")
        print("-" * 120)
        
        schema_info = []
        
        for col in df.columns:
            cleaned_col = clean_column_name(col)
            mysql_type, detail = infer_mysql_type(df[col], col)
            null_ratio = df[col].isnull().sum() / len(df) * 100
            
            schema_info.append({
                'original': col,
                'cleaned': cleaned_col,
                'type': mysql_type,
                'null_ratio': null_ratio,
                'detail': detail
            })
            
            print(f"{col:<25} {cleaned_col:<25} {mysql_type:<20} {null_ratio:>6.1f}% {detail:<30}")
        
        # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ
        print(f"\nğŸ“„ ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 5í–‰):")
        print("-" * 120)
        sample_df = df.head(5)
        print(sample_df.to_string(index=False, max_colwidth=15))
        
        # ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        print(f"\nğŸ“ˆ ë°ì´í„° í’ˆì§ˆ ë¶„ì„:")
        print("-" * 50)
        
        # ì „ì²´ NULL ë¹„ìœ¨
        total_nulls = df.isnull().sum().sum()
        total_cells = df.shape[0] * df.shape[1]
        null_percentage = total_nulls / total_cells * 100
        
        print(f"ì „ì²´ NULL ë¹„ìœ¨: {null_percentage:.1f}%")
        print(f"ì¤‘ë³µ í–‰ ìˆ˜: {df.duplicated().sum()}")
        
        # ê° ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ìˆ˜
        print(f"\nì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ìˆ˜:")
        for col in df.columns[:10]:  # ìƒìœ„ 10ê°œ ì»¬ëŸ¼ë§Œ
            unique_count = df[col].nunique()
            print(f"  {col}: {unique_count}ê°œ")
        
        # CREATE TABLE SQL ë¯¸ë¦¬ë³´ê¸°
        print(f"\nğŸ› ï¸ ìƒì„±ë  CREATE TABLE SQL:")
        print("-" * 80)
        
        columns = ["id INT AUTO_INCREMENT PRIMARY KEY"]
        
        for info in schema_info:
            null_clause = "NOT NULL" if info['null_ratio'] < 10 else ""
            default_clause = ""
            
            if info['type'].startswith("VARCHAR") or info['type'] in ["TEXT", "LONGTEXT"]:
                if null_clause:
                    default_clause = "DEFAULT ''"
            elif info['type'] == "DATE":
                default_clause = "DEFAULT NULL"
            
            column_def = f"`{info['cleaned']}` {info['type']} {null_clause} {default_clause}".strip()
            columns.append(column_def)
        
        columns.extend([
            "created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP",
            "updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP"
        ])
        
        sql = f"CREATE TABLE IF NOT EXISTS `{table_name}` (\n"
        sql += ",\n".join(f"    {col}" for col in columns)
        sql += f"\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;"
        
        print(sql)
        
        return {
            'table_name': table_name,
            'original_shape': df.shape,
            'schema_info': schema_info,
            'null_percentage': null_percentage,
            'duplicate_rows': df.duplicated().sum(),
            'sql': sql
        }
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ” CSV íŒŒì¼ ë¶„ì„ ë° í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ë¯¸ë¦¬ë³´ê¸°")
    print("=" * 80)
    
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ í™•ì¸
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # CSV íŒŒì¼ ëª©ë¡ í™•ì¸
    csv_files = [f for f in os.listdir(script_dir) if f.endswith('.csv')]
    
    if not csv_files:
        print("âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“„ ë°œê²¬ëœ CSV íŒŒì¼: {len(csv_files)}ê°œ")
    for i, f in enumerate(csv_files, 1):
        print(f"  {i}. {f}")
    
    # ë¶„ì„ ê²°ê³¼ ì €ì¥
    analysis_results = []
    
    for csv_file in csv_files:
        file_path = os.path.join(script_dir, csv_file)
        result = analyze_csv_file(file_path)
        if result:
            analysis_results.append(result)
    
    # ì „ì²´ ìš”ì•½
    if analysis_results:
        print(f"\nğŸ“Š ì „ì²´ ë¶„ì„ ìš”ì•½")
        print("=" * 80)
        
        total_tables = len(analysis_results)
        total_rows = sum(r['original_shape'][0] for r in analysis_results)
        total_columns = sum(r['original_shape'][1] for r in analysis_results)
        avg_null_percentage = sum(r['null_percentage'] for r in analysis_results) / total_tables
        
        print(f"ìƒì„±ë  í…Œì´ë¸” ìˆ˜: {total_tables}ê°œ")
        print(f"ì´ ë°ì´í„° í–‰ ìˆ˜: {total_rows:,}ê°œ")
        print(f"ì´ ì»¬ëŸ¼ ìˆ˜: {total_columns}ê°œ")
        print(f"í‰ê·  NULL ë¹„ìœ¨: {avg_null_percentage:.1f}%")
        
        print(f"\nğŸ—ï¸ ìƒì„±ë  í…Œì´ë¸” ëª©ë¡:")
        for i, result in enumerate(analysis_results, 1):
            rows, cols = result['original_shape']
            print(f"  {i:2d}. {result['table_name']:<20} ({rows:,}í–‰ x {cols}ì—´)")
        
        # SQL ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„± ì˜µì…˜
        print(f"\nğŸ’¾ SQL ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„± ì˜µì…˜:")
        choice = input("ëª¨ë“  CREATE TABLE SQLì„ íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        
        if choice in ['y', 'yes']:
            sql_file = os.path.join(script_dir, 'create_all_tables.sql')
            
            with open(sql_file, 'w', encoding='utf-8') as f:
                f.write("-- CSV íŒŒì¼ ê¸°ë°˜ í…Œì´ë¸” ìƒì„± ìŠ¤í¬ë¦½íŠ¸\n")
                f.write(f"-- ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"-- ì´ {total_tables}ê°œ í…Œì´ë¸”\n\n")
                
                f.write("USE dive_recruit;\n\n")
                
                for result in analysis_results:
                    f.write(f"-- í…Œì´ë¸”: {result['table_name']}\n")
                    f.write(f"-- ì›ë³¸ í¬ê¸°: {result['original_shape'][0]}í–‰ x {result['original_shape'][1]}ì—´\n")
                    f.write(f"{result['sql']}\n\n")
            
            print(f"âœ… SQL ìŠ¤í¬ë¦½íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {sql_file}")
    
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"1. ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•œ í›„ create_tables_from_csv.py ì‹¤í–‰")
    print(f"2. í…Œì´ë¸” ìƒì„± í›„ manage_tables.pyë¡œ ë°ì´í„° í™•ì¸")

if __name__ == "__main__":
    main()
